{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of DCGAN without any improvement\n",
    "- Number of epochs: 50\n",
    "- lr: 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': '../data/ut-zap50k/Shoes/Sneakers_and_athletic_shoes/',\n",
    "    'epochs': 50,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'image_size': 136,\n",
    "    'scale_size': 64,\n",
    "    'z_dim': 100,\n",
    "    'G_features': 64,\n",
    "    'D_features': 64,\n",
    "    'image_channels': 3,\n",
    "    'beta1': 0.5,\n",
    "    'cuda': True,\n",
    "    'seed': 7,\n",
    "    'workers': 2,\n",
    "    'results': './resultsDCGAN1_0801/'\n",
    "    \n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "args.image_results = args.results + 'images/'\n",
    "args.loss_results = args.results + 'loss/'\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.makedirs(args.data_path)\n",
    "if not os.path.isdir(args.results):\n",
    "    os.makedirs(args.results)\n",
    "if not os.path.isdir(args.image_results):\n",
    "    os.makedirs(args.image_results)\n",
    "if not os.path.isdir(args.loss_results):\n",
    "    os.makedirs(args.loss_results)\n",
    "    \n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: all iamges have size 136x102**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from folder import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "to_image = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(image_root, batch_size, scale_size, num_workers=2, shuffle=True):\n",
    "    #image_root = os.path.join(root, 'splits', split)\n",
    "    dataset = ImageFolder(root=image_root, transform=transforms.Compose([\n",
    "            transforms.Pad(34, fill=(255, 255, 255)), # padding images with (255,255,255) --> pad 255 in 3 channels\n",
    "            transforms.CenterCrop((136,136)),\n",
    "            transforms.Scale(scale_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=int(num_workers))\n",
    "    #data_loader.shape = [int(num) for num in dataset[0][0].size()]\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12856 images in subfolders of: ./data/ut-zap50k/Shoes/Sneakers_and_athletic_shoes/\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_loader(args.data_path, args.batch_size, args.scale_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x64x64]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_image = 0\n",
    "for data, _ in dataloader:\n",
    "    print(data[0])\n",
    "    test_image = data[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAQRUlEQVR4nO2aWY9dx3HHq6q7z3b3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\nrkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F30D42462E8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_image(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(args.z_dim, args.G_features * 8,\n",
    "                               4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(args.G_features * 8, args.G_features * 4,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(args.G_features * 4, args.G_features * 2,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(args.G_features * 2, args.G_features,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(args.G_features, args.image_channels,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # custom weight initialization\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                init.normal(m.weight, mean=0, std=0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.normal(m.weight, mean=1, std=0.02)\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(args.image_channels, args.D_features,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(args.D_features, args.D_features * 2,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(args.D_features * 2, args.D_features * 4,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(args.D_features * 4, args.D_features * 8,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(args.D_features * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # custom weight initialization\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                init.normal(m.weight, mean=0, std=0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.normal(m.weight, mean=1, std=0.02)\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Results():\n",
    "    def __init__(self, results_path):\n",
    "        self.D_losses = []\n",
    "        self.G_losses = []\n",
    "        self.D_reals = []\n",
    "        self.D_fakes = []\n",
    "        self.G_reals = []\n",
    "        self.results_path = results_path\n",
    "    \n",
    "    def save_losses(self, D_loss, G_loss, D_real, D_fake, G_real):\n",
    "        self.D_losses.append(D_loss)\n",
    "        self.G_losses.append(G_loss)\n",
    "        self.D_reals.append(D_real)\n",
    "        self.D_fakes.append(D_fake)\n",
    "        self.G_reals.append(G_real)\n",
    "        \n",
    "    def save_to_disk(self):\n",
    "        f = open(self.results_path + \"D_losses.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_losses, f)\n",
    "        f= open(self.results_path + \"G_losses.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_losses, f)\n",
    "        f = open(self.results_path + \"D_reals.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_reals, f)\n",
    "        f = open(self.results_path + \"D_fakes.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_fakes, f)\n",
    "        f = open(self.results_path + \"G_reals.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_reals, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(args, data_loader, netG, netD, G_optimizer, D_optimizer,\n",
    "          criterion, epoch, result_losses):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    D_reals = AverageValueMeter()\n",
    "    D_fakes = AverageValueMeter()\n",
    "    G_reals = AverageValueMeter()\n",
    "    \n",
    "    start = time.time()\n",
    "    # call Variable after .cuda()\n",
    "    for i, (real, _) in enumerate(data_loader):\n",
    "        batch_size = real.size(0)\n",
    "        real_label = torch.ones(batch_size)\n",
    "        fake_label = torch.zeros(batch_size)\n",
    "        z = torch.randn(batch_size, args.z_dim, 1, 1)\n",
    "        if args.cuda:\n",
    "            real_label = real_label.cuda()\n",
    "            fake_label = fake_label.cuda()\n",
    "            real = real.cuda()\n",
    "            z = z.cuda()\n",
    "        real_label = Variable(real_label)\n",
    "        fake_label = Variable(fake_label)\n",
    "        real = Variable(real)\n",
    "        z = Variable(z)\n",
    "        \n",
    "        real_output = netD(real)\n",
    "        D_real_loss = criterion(real_output, real_label)\n",
    "        D_real = real_output.data.mean()\n",
    "        \n",
    "        fake = netG(z)\n",
    "        fake_output = netD(fake.detach())\n",
    "        D_fake_loss = criterion(fake_output, fake_label)\n",
    "        D_fake = fake_output.data.mean()\n",
    "        \n",
    "        D_loss = D_real_loss + D_fake_loss\n",
    "        netD.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        \n",
    "        output = netD(fake)\n",
    "        G_loss = criterion(output, real_label)\n",
    "        G_real = output.data.mean()\n",
    "        netG.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        D_losses.add(D_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        G_losses.add(G_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        D_reals.add(D_real * batch_size, batch_size)\n",
    "        D_fakes.add(D_fake * batch_size, batch_size)\n",
    "        G_reals.add(G_real * batch_size, batch_size)\n",
    "        \n",
    "    print(\"=> EPOCH {} | Time: {}s | D_loss: {:.4f} | G_loss: {:.4f}\"\n",
    "          \" | D_real: {:.4f} | D_fake: {:.4f} | G_real: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start), D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0]))\n",
    "    result_losses.save_losses(D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(args, netG, epoch):\n",
    "    z = torch.randn(args.batch_size, args.z_dim, 1, 1)\n",
    "    if args.cuda:\n",
    "        z = z.cuda()\n",
    "    fake = netG(Variable(z, volatile=True))\n",
    "    save_image(fake.data.cpu(), os.path.join(args.results,\n",
    "        \"fake_sample_epoch_{:02d}.png\".format(epoch)), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG()\n",
    "netD = _netD()\n",
    "criterion = nn.BCELoss()\n",
    "if args.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_optimizer = optim.Adam(netD.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999), weight_decay=1e-4)\n",
    "G_optimizer = optim.Adam(netG.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 0 | Time: 11s | D_loss: 0.7299 | G_loss: 9.6187 | D_real: 0.8492 | D_fake: 0.1635 | G_real: 0.0280\n",
      "=> EPOCH 1 | Time: 11s | D_loss: 0.6525 | G_loss: 4.6417 | D_real: 0.8053 | D_fake: 0.1957 | G_real: 0.0621\n",
      "=> EPOCH 2 | Time: 11s | D_loss: 0.7598 | G_loss: 3.6532 | D_real: 0.7665 | D_fake: 0.2285 | G_real: 0.1025\n",
      "=> EPOCH 3 | Time: 11s | D_loss: 0.8327 | G_loss: 3.2159 | D_real: 0.7418 | D_fake: 0.2602 | G_real: 0.1201\n",
      "=> EPOCH 4 | Time: 11s | D_loss: 0.8209 | G_loss: 2.9645 | D_real: 0.7330 | D_fake: 0.2645 | G_real: 0.1273\n",
      "=> EPOCH 5 | Time: 11s | D_loss: 0.8236 | G_loss: 2.9504 | D_real: 0.7316 | D_fake: 0.2682 | G_real: 0.1324\n",
      "=> EPOCH 6 | Time: 11s | D_loss: 0.8380 | G_loss: 2.8516 | D_real: 0.7238 | D_fake: 0.2752 | G_real: 0.1352\n",
      "=> EPOCH 7 | Time: 11s | D_loss: 0.8326 | G_loss: 2.7993 | D_real: 0.7234 | D_fake: 0.2746 | G_real: 0.1377\n",
      "=> EPOCH 8 | Time: 11s | D_loss: 0.8280 | G_loss: 2.7521 | D_real: 0.7232 | D_fake: 0.2747 | G_real: 0.1368\n",
      "=> EPOCH 9 | Time: 11s | D_loss: 0.8233 | G_loss: 2.7742 | D_real: 0.7244 | D_fake: 0.2739 | G_real: 0.1424\n",
      "=> EPOCH 10 | Time: 12s | D_loss: 0.7839 | G_loss: 2.7777 | D_real: 0.7323 | D_fake: 0.2683 | G_real: 0.1353\n",
      "=> EPOCH 11 | Time: 12s | D_loss: 0.8215 | G_loss: 2.6609 | D_real: 0.7226 | D_fake: 0.2731 | G_real: 0.1483\n",
      "=> EPOCH 12 | Time: 12s | D_loss: 0.8069 | G_loss: 2.6973 | D_real: 0.7257 | D_fake: 0.2736 | G_real: 0.1416\n",
      "=> EPOCH 13 | Time: 12s | D_loss: 0.8268 | G_loss: 2.6974 | D_real: 0.7205 | D_fake: 0.2789 | G_real: 0.1429\n",
      "=> EPOCH 14 | Time: 12s | D_loss: 0.8162 | G_loss: 2.6736 | D_real: 0.7245 | D_fake: 0.2742 | G_real: 0.1429\n",
      "=> EPOCH 15 | Time: 12s | D_loss: 0.7934 | G_loss: 2.7017 | D_real: 0.7266 | D_fake: 0.2711 | G_real: 0.1390\n",
      "=> EPOCH 16 | Time: 12s | D_loss: 0.7748 | G_loss: 2.6896 | D_real: 0.7331 | D_fake: 0.2676 | G_real: 0.1391\n",
      "=> EPOCH 17 | Time: 12s | D_loss: 0.8343 | G_loss: 2.6673 | D_real: 0.7213 | D_fake: 0.2760 | G_real: 0.1425\n",
      "=> EPOCH 18 | Time: 12s | D_loss: 0.7171 | G_loss: 2.6383 | D_real: 0.7453 | D_fake: 0.2549 | G_real: 0.1350\n",
      "=> EPOCH 19 | Time: 12s | D_loss: 0.6704 | G_loss: 2.7486 | D_real: 0.7581 | D_fake: 0.2393 | G_real: 0.1278\n",
      "=> EPOCH 20 | Time: 12s | D_loss: 0.8016 | G_loss: 2.8124 | D_real: 0.7400 | D_fake: 0.2607 | G_real: 0.1399\n",
      "=> EPOCH 21 | Time: 12s | D_loss: 0.6286 | G_loss: 2.7583 | D_real: 0.7699 | D_fake: 0.2290 | G_real: 0.1220\n",
      "=> EPOCH 22 | Time: 12s | D_loss: 0.6208 | G_loss: 2.8709 | D_real: 0.7772 | D_fake: 0.2234 | G_real: 0.1195\n",
      "=> EPOCH 23 | Time: 12s | D_loss: 0.6541 | G_loss: 2.9211 | D_real: 0.7707 | D_fake: 0.2268 | G_real: 0.1219\n",
      "=> EPOCH 24 | Time: 12s | D_loss: 0.7310 | G_loss: 2.8961 | D_real: 0.7665 | D_fake: 0.2323 | G_real: 0.1390\n",
      "=> EPOCH 25 | Time: 12s | D_loss: 0.5649 | G_loss: 2.8595 | D_real: 0.7916 | D_fake: 0.2085 | G_real: 0.1116\n",
      "=> EPOCH 26 | Time: 12s | D_loss: 0.5817 | G_loss: 2.9776 | D_real: 0.7934 | D_fake: 0.2064 | G_real: 0.1125\n",
      "=> EPOCH 27 | Time: 12s | D_loss: 0.4747 | G_loss: 3.1351 | D_real: 0.8192 | D_fake: 0.1800 | G_real: 0.0966\n",
      "=> EPOCH 28 | Time: 12s | D_loss: 0.5111 | G_loss: 3.2509 | D_real: 0.8125 | D_fake: 0.1866 | G_real: 0.0995\n",
      "=> EPOCH 29 | Time: 12s | D_loss: 0.4674 | G_loss: 3.3153 | D_real: 0.8259 | D_fake: 0.1735 | G_real: 0.0890\n",
      "=> EPOCH 30 | Time: 12s | D_loss: 0.5927 | G_loss: 3.2095 | D_real: 0.8160 | D_fake: 0.1831 | G_real: 0.1069\n",
      "=> EPOCH 31 | Time: 12s | D_loss: 0.4071 | G_loss: 3.3534 | D_real: 0.8435 | D_fake: 0.1554 | G_real: 0.0845\n",
      "=> EPOCH 32 | Time: 12s | D_loss: 0.4012 | G_loss: 3.5534 | D_real: 0.8478 | D_fake: 0.1519 | G_real: 0.0766\n",
      "=> EPOCH 33 | Time: 12s | D_loss: 0.3499 | G_loss: 3.6335 | D_real: 0.8636 | D_fake: 0.1364 | G_real: 0.0708\n",
      "=> EPOCH 34 | Time: 12s | D_loss: 1.4130 | G_loss: 3.0666 | D_real: 0.7219 | D_fake: 0.2808 | G_real: 0.1951\n",
      "=> EPOCH 35 | Time: 12s | D_loss: 0.3755 | G_loss: 3.1814 | D_real: 0.8503 | D_fake: 0.1501 | G_real: 0.0823\n",
      "=> EPOCH 36 | Time: 12s | D_loss: 0.2872 | G_loss: 3.5161 | D_real: 0.8814 | D_fake: 0.1180 | G_real: 0.0661\n",
      "=> EPOCH 37 | Time: 12s | D_loss: 0.4384 | G_loss: 3.5374 | D_real: 0.8434 | D_fake: 0.1559 | G_real: 0.0900\n",
      "=> EPOCH 38 | Time: 12s | D_loss: 0.3061 | G_loss: 3.6901 | D_real: 0.8795 | D_fake: 0.1198 | G_real: 0.0653\n",
      "=> EPOCH 39 | Time: 12s | D_loss: 0.9758 | G_loss: 2.9361 | D_real: 0.7568 | D_fake: 0.2430 | G_real: 0.1999\n",
      "=> EPOCH 40 | Time: 12s | D_loss: 0.4779 | G_loss: 3.2255 | D_real: 0.8278 | D_fake: 0.1717 | G_real: 0.0943\n",
      "=> EPOCH 41 | Time: 12s | D_loss: 0.2543 | G_loss: 3.7009 | D_real: 0.8959 | D_fake: 0.1052 | G_real: 0.0588\n",
      "=> EPOCH 42 | Time: 12s | D_loss: 0.2681 | G_loss: 3.8399 | D_real: 0.8922 | D_fake: 0.1064 | G_real: 0.0595\n",
      "=> EPOCH 43 | Time: 12s | D_loss: 0.3893 | G_loss: 3.8493 | D_real: 0.8691 | D_fake: 0.1300 | G_real: 0.0769\n",
      "=> EPOCH 44 | Time: 12s | D_loss: 0.3142 | G_loss: 4.0175 | D_real: 0.8887 | D_fake: 0.1112 | G_real: 0.0643\n",
      "=> EPOCH 45 | Time: 12s | D_loss: 0.3591 | G_loss: 3.9411 | D_real: 0.8813 | D_fake: 0.1178 | G_real: 0.0690\n",
      "=> EPOCH 46 | Time: 12s | D_loss: 0.2164 | G_loss: 3.9958 | D_real: 0.9101 | D_fake: 0.0892 | G_real: 0.0460\n",
      "=> EPOCH 47 | Time: 12s | D_loss: 0.6599 | G_loss: 3.4744 | D_real: 0.8202 | D_fake: 0.1794 | G_real: 0.1362\n",
      "=> EPOCH 48 | Time: 12s | D_loss: 0.3011 | G_loss: 3.8945 | D_real: 0.8845 | D_fake: 0.1163 | G_real: 0.0581\n",
      "=> EPOCH 49 | Time: 12s | D_loss: 0.1631 | G_loss: 4.1612 | D_real: 0.9295 | D_fake: 0.0703 | G_real: 0.0373\n"
     ]
    }
   ],
   "source": [
    "result_losses = Results(args.loss_results)\n",
    "for epoch in range(0, args.epochs):\n",
    "    train(args, dataloader, netG, netD, G_optimizer, D_optimizer,\n",
    "          criterion, epoch, result_losses)\n",
    "    generate(args, netG, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_losses.save_to_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one REAL Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample, _ = iter(dataloader).next()\n",
    "save_image(sample, os.path.join(args.results, \"real_sample.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "246px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
