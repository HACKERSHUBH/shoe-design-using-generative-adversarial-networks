{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of DCGAN with normalize input and one-sided label smoothing:\n",
    "- Number of epochs: 100\n",
    "- lr: 0.0002\n",
    "- Add results dir for images and loss\n",
    "- Add weight_decay: 1e-4\n",
    "\n",
    "- input: normalize (0.5, 0.5, 0.5)\n",
    "- sided_label: 0.9 ```torch.from_numpy(np.full(batch_size, 0.9, np.float32))```\n",
    "- Freezing: stop update D when loss D < 0.7 loss G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1568\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[0m\u001b[01;34m7 For All Mankind Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34madidas\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34madidas by Stella McCartney\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34madidas Golf\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34madidas Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34madidas Originals\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34madidas Originals Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34madidas Outdoor\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34madidas Running\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34madidas Y-3 by Yohji Yamamoto\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAetrex\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAgatha Ruiz De La Prada Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAhnu\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mALDO\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAlexander McQueen\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAllrounder by Mephisto\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAltra Zero Drop Footwear\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAmiana\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAnne Klein\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mArcopedico\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAriat\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mArmani Jeans\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAshworth\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 20480  4월 23 13:42 \u001b[01;34mASICS\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mASICS Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAsolo\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAster Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAvia\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mAxion\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBC Footwear\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBeeko\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBen Sherman\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBetsey Johnson\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBikkembergs\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBloch\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBloch Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBlowfish\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBody Glove\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBogs\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBorn\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBOSS Green\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBOSS Orange\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBottega Veneta\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mBrooks\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBrooks Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mBurberry\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCallaway\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCall it SPRING\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCalvin Klein\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCalvin Klein Jeans\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCamper\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCamper Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCapezio\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCapezio Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCaterpillar\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mChaco\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mChaco Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mChicago Skates\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mChrome\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCienta Kids Shoes\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCirca\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCirca Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mClae\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mClarks\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCobian\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCole Haan\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCole Haan Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mColumbia\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mConverse\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mConverse by John Varvatos\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mConverse Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCostume National\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCreative Recreation\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCreative Recreation Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCrocs\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCrocs Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mCushe\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDansko\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDavid Tate\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDC\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mDC Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDeer Stags\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDexter Bowling\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDiadora\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDiadora Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDiesel\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDirk Bikkembergs\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDKNY\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDolce & Gabbana\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDrew\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDr. Martens\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDSQUARED2\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDunham\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mDVS Shoe Company\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEasy Spirit\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mECCO\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mECCO Golf\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEcco Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mECCO Sport\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEd Hardy\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEktelon\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mElement\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mElizabeth and James\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEl Naturalista\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEmerald by Element\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEmerica\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34metnies\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34metnies Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mEVOLV\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFallen\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFila\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFinn Comfort\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFitFlop\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFive Ten\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFox\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFratelli Rossetti\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFred Perry\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFrye\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mFrye Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGabor\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGarmont\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGBX\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGeneric Surplus\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGeox Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGiro\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGiuseppe Zanotti\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGlobe\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGlobe Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGola\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGoLite\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGravis\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGUESS\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mGUESS Kids'\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHabitat\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHeelys\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHi-Tec\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHi-Tec Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHoka One One\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHUGO\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHush Puppies\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mHush Puppies Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34minov-8\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mIpath\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJ-41\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJambu\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJambu Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJessica Simpson Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJohn Varvatos\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJosef Seibel\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJuicy Couture\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJuicy Couture Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJumping Jacks Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mJust Cavalli\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mK2 Skates\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKalso Earth\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKamik\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKangaROOS\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKangaROOS Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKeds\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKeds Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKeen\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKeen Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKeen Utility\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKenneth Cole New York\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKenneth Cole Reaction\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKenneth Cole Reaction Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKhombu\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKid Express\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mKORS Michael Kors Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mK-Swiss\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mK-Swiss Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mLacoste\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLacoste Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLakai\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLa Sportiva\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLevi's&#174; Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLevi's&#174; Shoes\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLowa\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mLugz\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMacbeth\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMadden Girl\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMarc by Marc Jacobs\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMarc Jacobs\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMephisto\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mMerrell\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMerrell Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMe Too Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMIA\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMICHAEL Michael Kors\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMICHAEL Michael Kors Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mMizuno\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMizuno Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMontrail\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMorgan&Milo Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMoschino\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMountrek\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMOZO\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mMunro American\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNative Kids Shoes\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNative Shoes\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNaturino\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 20480  4월 23 13:42 \u001b[01;34mNew Balance\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNew Balance Classics\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mNew Balance Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNewton Running\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 36864  4월 23 13:42 \u001b[01;34mNike\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNike Action\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNike Action Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNike Golf\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 20480  4월 23 13:42 \u001b[01;34mNike Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNine West Sneakers\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNO SOX\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNunn Bush\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mNurse Mates\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOakley\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOcean Minded\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOluKai\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOluKai Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mO'Neill\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOnitsuka Tiger by Asics\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOnitsuka Tiger Kids by Asics\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOriginal Penguin\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOrthaheel\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOsiris\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mOsiris Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPablosky Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPalladium\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPalladium Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPatagonia\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPaul Smith\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPaul Smith Junior\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPearl Izumi\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mpediped\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPF Flyers\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPF Flyers Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPikolinos\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPolo Ralph Lauren\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPolo Ralph Lauren Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPrimigi Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPrince\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPrivo by Clarks\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPro-Keds\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPropet\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 28672  4월 23 13:42 \u001b[01;34mPUMA\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mPuma Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mPUMA Sport Fashion\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mQuiksilver\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRachel Zoe\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRagg Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRalph Lauren Layette Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mReebok\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mReebok Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mReebok Lifestyle\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mReebok Team\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mReef\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mReport\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRieker\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRocket Dog\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRockport\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRollerblade\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRomika\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRoxy\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mRyka\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSalomon\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSalomon Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSalvatore Ferragamo\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSanuk\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSanuk Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mSaucony\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSaucony Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSaucony Originals\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mScarpa\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSchool Issue\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSeaVees\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSebago\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSee Kai Run Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mShimano\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSIDI\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 20480  4월 23 13:42 \u001b[01;34mSKECHERS\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSKECHERS KIDS\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSKECHERS Work\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSLVR\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSoft Style\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSpeedo\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSperry Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSperry Top-Sider\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSpira\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSteve Madden\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSteve Madden Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mStride Rite\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mStuart Weitzman\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mStuart Weitzman for The Cool People\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSuperga\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSuperga Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mSupra\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTecnica\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTed Baker\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTeva\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTeva Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mThe North Face\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mThe North Face Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTIC TAC TOES\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTimberland\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTimberland Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTimberland PRO\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTommy Bahama\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTommy Hilfiger\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTommy Hilfiger Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTravis Mathew\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTretorn\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTretorn Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTrue Religion\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTsubo\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTsukihoshi Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mTwig Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mUGG\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mUGG Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mUmi Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mUnder Armour\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mUnder Armour Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mVans\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle 12288  4월 23 13:42 \u001b[01;34mVans Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVasque\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVenettini Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVersace Collection\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVibram FiveFingers\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVivienne Westwood\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVivobarefoot\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVOLATILE\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mVolatile Kids\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mWilson\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mWolverine\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mZamberlan\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mZero\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mZigi\u001b[0m/\r\n",
      "drwxrwxr-x 2 hminle  4096  4월 23 13:42 \u001b[01;34mZoot Sports\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ll ./data/ut-zap50k/Shoes/Sneakers_and_athletic_shoes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': './data/ut-zap50k/Shoes/Sneakers_and_athletic_shoes/',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'image_size': 136,\n",
    "    'scale_size': 64,\n",
    "    'z_dim': 100,\n",
    "    'G_features': 64,\n",
    "    'D_features': 64,\n",
    "    'image_channels': 3,\n",
    "    'beta1': 0.5,\n",
    "    'cuda': True,\n",
    "    'seed': 7,\n",
    "    'workers': 2,\n",
    "    'results': './resultsDCGAN4_0529/'\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "args.image_results = args.results + 'images/'\n",
    "args.loss_results = args.results + 'loss/'\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.makedirs(args.data_path)\n",
    "if not os.path.isdir(args.results):\n",
    "    os.makedirs(args.results)\n",
    "if not os.path.isdir(args.image_results):\n",
    "    os.makedirs(args.image_results)\n",
    "if not os.path.isdir(args.loss_results):\n",
    "    os.makedirs(args.loss_results)\n",
    "    \n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: all iamges have size 136x102**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from folder import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "to_image = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(image_root, batch_size, scale_size, num_workers=2, shuffle=True):\n",
    "    #image_root = os.path.join(root, 'splits', split)\n",
    "    dataset = ImageFolder(root=image_root, transform=transforms.Compose([\n",
    "            transforms.Pad(34, fill=(255, 255, 255)), # padding images with (255,255,255) --> pad 255 in 3 channels\n",
    "            transforms.CenterCrop((136,136)),\n",
    "            transforms.Scale(scale_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=int(num_workers))\n",
    "    #data_loader.shape = [int(num) for num in dataset[0][0].size()]\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12856 images in subfolders of: ./data/ut-zap50k/Shoes/Sneakers_and_athletic_shoes/\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_loader(args.data_path, args.batch_size, args.scale_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x64x64]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_image = 0\n",
    "for data, _ in dataloader:\n",
    "    print(data[0])\n",
    "    test_image = data[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAARJklEQVR4nO1af3Bc1XU+PjncXF8e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\ngg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F505C5EF3C8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_image(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(args.z_dim, args.G_features * 8,\n",
    "                               4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(args.G_features * 8, args.G_features * 4,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(args.G_features * 4, args.G_features * 2,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(args.G_features * 2, args.G_features,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(args.G_features, args.image_channels,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # custom weight initialization\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                init.normal(m.weight, mean=0, std=0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.normal(m.weight, mean=1, std=0.02)\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(args.image_channels, args.D_features,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(args.D_features, args.D_features * 2,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(args.D_features * 2, args.D_features * 4,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(args.D_features * 4, args.D_features * 8,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(args.D_features * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # custom weight initialization\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                init.normal(m.weight, mean=0, std=0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.normal(m.weight, mean=1, std=0.02)\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Results():\n",
    "    def __init__(self, results_path):\n",
    "        self.D_losses = []\n",
    "        self.G_losses = []\n",
    "        self.D_reals = []\n",
    "        self.D_fakes = []\n",
    "        self.G_reals = []\n",
    "        self.results_path = results_path\n",
    "    \n",
    "    def save_losses(self, D_loss, G_loss, D_real, D_fake, G_real):\n",
    "        self.D_losses.append(D_loss)\n",
    "        self.G_losses.append(G_loss)\n",
    "        self.D_reals.append(D_real)\n",
    "        self.D_fakes.append(D_fake)\n",
    "        self.G_reals.append(G_real)\n",
    "        \n",
    "    def save_to_disk(self):\n",
    "        f = open(self.results_path + \"D_losses.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_losses, f)\n",
    "        f= open(self.results_path + \"G_losses.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_losses, f)\n",
    "        f = open(self.results_path + \"D_reals.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_reals, f)\n",
    "        f = open(self.results_path + \"D_fakes.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_fakes, f)\n",
    "        f = open(self.results_path + \"G_reals.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_reals, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.full(5, 1, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = torch.from_numpy(np.full(5, 1, np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_label = torch.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.ByteTensor of size 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c == real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(args, data_loader, netG, netD, G_optimizer, D_optimizer,\n",
    "          criterion, epoch, result_losses):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    D_reals = AverageValueMeter()\n",
    "    D_fakes = AverageValueMeter()\n",
    "    G_reals = AverageValueMeter()\n",
    "    \n",
    "    start = time.time()\n",
    "    # call Variable after .cuda()\n",
    "    for i, (real, _) in enumerate(data_loader):\n",
    "        batch_size = real.size(0)\n",
    "        real_label = torch.from_numpy(np.full(batch_size, 0.9, np.float32)) #modify here\n",
    "        fake_label = torch.zeros(batch_size)\n",
    "        z = torch.randn(batch_size, args.z_dim, 1, 1)\n",
    "        \n",
    "        if args.cuda:\n",
    "            real_label = real_label.cuda()\n",
    "            fake_label = fake_label.cuda()\n",
    "            real = real.cuda()\n",
    "            z = z.cuda()\n",
    "        real_label = Variable(real_label)\n",
    "        fake_label = Variable(fake_label)\n",
    "        real = Variable(real)\n",
    "        z = Variable(z)\n",
    "        \n",
    "        if D_losses.value()[0] < 0.7*G_losses.value()[0]:\n",
    "            # Stop training D\n",
    "            #----------TRAIN D---------------\n",
    "            # train with real\n",
    "            real_output = netD(real)\n",
    "            D_real_loss = criterion(real_output, real_label)\n",
    "            D_real = real_output.data.mean()\n",
    "        \n",
    "            # train with fake\n",
    "            fake = netG(z)\n",
    "            fake_output = netD(fake.detach())\n",
    "            D_fake_loss = criterion(fake_output, fake_label)\n",
    "            D_fake = fake_output.data.mean()\n",
    "        \n",
    "            # loss D\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "            #netD.zero_grad()\n",
    "            #D_loss.backward()\n",
    "            #D_optimizer.step()\n",
    "            \n",
    "            #----------TRAIN G---------------\n",
    "            output = netD(fake)\n",
    "            G_loss = criterion(output, real_label)\n",
    "            G_real = output.data.mean()\n",
    "            netG.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()    \n",
    "        else:\n",
    "            #----------TRAIN D---------------\n",
    "            # train with real\n",
    "            real_output = netD(real)\n",
    "            D_real_loss = criterion(real_output, real_label)\n",
    "            D_real = real_output.data.mean()\n",
    "        \n",
    "            # train with fake\n",
    "            fake = netG(z)\n",
    "            fake_output = netD(fake.detach())\n",
    "            D_fake_loss = criterion(fake_output, fake_label)\n",
    "            D_fake = fake_output.data.mean()\n",
    "        \n",
    "            # loss D\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "            netD.zero_grad()\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "            \n",
    "            #----------TRAIN G---------------\n",
    "            output = netD(fake)\n",
    "            G_loss = criterion(output, real_label)\n",
    "            G_real = output.data.mean()\n",
    "            netG.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # update loss\n",
    "        D_losses.add(D_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        G_losses.add(G_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        D_reals.add(D_real * batch_size, batch_size)\n",
    "        D_fakes.add(D_fake * batch_size, batch_size)\n",
    "        G_reals.add(G_real * batch_size, batch_size)\n",
    "        \n",
    "    print(\"=> EPOCH {} | Time: {}s | D_loss: {:.4f} | G_loss: {:.4f}\"\n",
    "          \" | D_real: {:.4f} | D_fake: {:.4f} | G_real: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start), D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0]))\n",
    "    result_losses.save_losses(D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(args, netG, epoch):\n",
    "    z = torch.randn(args.batch_size, args.z_dim, 1, 1)\n",
    "    if args.cuda:\n",
    "        z = z.cuda()\n",
    "    fake = netG(Variable(z, volatile=True))\n",
    "    save_image(fake.data.cpu(), os.path.join(args.image_results,\n",
    "        \"fake_sample_epoch_{:02d}.png\".format(epoch)), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG()\n",
    "netD = _netD()\n",
    "criterion = nn.BCELoss()\n",
    "if args.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_optimizer = optim.Adam(netD.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999), weight_decay=1e-4)\n",
    "G_optimizer = optim.Adam(netG.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 0 | Time: 133s | D_loss: 2.7062 | G_loss: 3.8682 | D_real: 0.5840 | D_fake: 0.5149 | G_real: 0.3694\n",
      "=> EPOCH 1 | Time: 40s | D_loss: 1.3951 | G_loss: 1.9948 | D_real: 0.5222 | D_fake: 0.3088 | G_real: 0.2081\n",
      "=> EPOCH 2 | Time: 41s | D_loss: 1.3260 | G_loss: 1.8864 | D_real: 0.5048 | D_fake: 0.3011 | G_real: 0.2026\n",
      "=> EPOCH 3 | Time: 42s | D_loss: 1.2194 | G_loss: 1.7383 | D_real: 0.5373 | D_fake: 0.3153 | G_real: 0.2167\n",
      "=> EPOCH 4 | Time: 44s | D_loss: 1.2350 | G_loss: 1.7676 | D_real: 0.5243 | D_fake: 0.3063 | G_real: 0.2103\n",
      "=> EPOCH 5 | Time: 44s | D_loss: 1.2612 | G_loss: 1.8045 | D_real: 0.5164 | D_fake: 0.3127 | G_real: 0.2068\n",
      "=> EPOCH 6 | Time: 44s | D_loss: 1.2620 | G_loss: 1.8004 | D_real: 0.5370 | D_fake: 0.3233 | G_real: 0.2135\n",
      "=> EPOCH 7 | Time: 45s | D_loss: 1.2019 | G_loss: 1.7154 | D_real: 0.5465 | D_fake: 0.3256 | G_real: 0.2124\n",
      "=> EPOCH 8 | Time: 45s | D_loss: 1.2055 | G_loss: 1.7162 | D_real: 0.5451 | D_fake: 0.3320 | G_real: 0.2071\n",
      "=> EPOCH 9 | Time: 45s | D_loss: 1.2068 | G_loss: 1.7180 | D_real: 0.5383 | D_fake: 0.3316 | G_real: 0.2107\n",
      "=> EPOCH 10 | Time: 44s | D_loss: 1.2082 | G_loss: 1.7215 | D_real: 0.5353 | D_fake: 0.3276 | G_real: 0.2082\n",
      "=> EPOCH 11 | Time: 45s | D_loss: 1.2085 | G_loss: 1.7205 | D_real: 0.5318 | D_fake: 0.3171 | G_real: 0.2059\n",
      "=> EPOCH 12 | Time: 44s | D_loss: 1.2083 | G_loss: 1.7190 | D_real: 0.5324 | D_fake: 0.3209 | G_real: 0.2084\n",
      "=> EPOCH 13 | Time: 45s | D_loss: 1.1692 | G_loss: 1.6713 | D_real: 0.5478 | D_fake: 0.3247 | G_real: 0.2147\n",
      "=> EPOCH 14 | Time: 45s | D_loss: 1.1643 | G_loss: 1.6550 | D_real: 0.5505 | D_fake: 0.3298 | G_real: 0.2209\n",
      "=> EPOCH 15 | Time: 45s | D_loss: 1.1806 | G_loss: 1.6792 | D_real: 0.5403 | D_fake: 0.3192 | G_real: 0.2144\n",
      "=> EPOCH 16 | Time: 44s | D_loss: 1.1908 | G_loss: 1.6802 | D_real: 0.5403 | D_fake: 0.3219 | G_real: 0.2169\n",
      "=> EPOCH 17 | Time: 44s | D_loss: 1.1798 | G_loss: 1.6799 | D_real: 0.5279 | D_fake: 0.3106 | G_real: 0.2107\n",
      "=> EPOCH 18 | Time: 44s | D_loss: 1.1531 | G_loss: 1.6480 | D_real: 0.5467 | D_fake: 0.3163 | G_real: 0.2178\n",
      "=> EPOCH 19 | Time: 43s | D_loss: 1.1899 | G_loss: 1.6930 | D_real: 0.5303 | D_fake: 0.3143 | G_real: 0.2131\n",
      "=> EPOCH 20 | Time: 43s | D_loss: 1.1575 | G_loss: 1.6456 | D_real: 0.5392 | D_fake: 0.3150 | G_real: 0.2198\n",
      "=> EPOCH 21 | Time: 43s | D_loss: 1.1750 | G_loss: 1.6777 | D_real: 0.5206 | D_fake: 0.3017 | G_real: 0.2112\n",
      "=> EPOCH 22 | Time: 43s | D_loss: 1.1891 | G_loss: 1.6995 | D_real: 0.5314 | D_fake: 0.3058 | G_real: 0.2130\n",
      "=> EPOCH 23 | Time: 42s | D_loss: 1.1456 | G_loss: 1.6348 | D_real: 0.5329 | D_fake: 0.3017 | G_real: 0.2171\n",
      "=> EPOCH 24 | Time: 43s | D_loss: 1.1658 | G_loss: 1.6628 | D_real: 0.5403 | D_fake: 0.3104 | G_real: 0.2191\n",
      "=> EPOCH 25 | Time: 41s | D_loss: 1.1473 | G_loss: 1.6337 | D_real: 0.5257 | D_fake: 0.2988 | G_real: 0.2185\n",
      "=> EPOCH 26 | Time: 41s | D_loss: 1.1260 | G_loss: 1.6111 | D_real: 0.5293 | D_fake: 0.2940 | G_real: 0.2221\n",
      "=> EPOCH 27 | Time: 41s | D_loss: 1.1722 | G_loss: 1.6632 | D_real: 0.5176 | D_fake: 0.2938 | G_real: 0.2162\n",
      "=> EPOCH 28 | Time: 40s | D_loss: 1.1595 | G_loss: 1.6549 | D_real: 0.5024 | D_fake: 0.2823 | G_real: 0.2119\n",
      "=> EPOCH 29 | Time: 42s | D_loss: 1.1404 | G_loss: 1.6308 | D_real: 0.5452 | D_fake: 0.3031 | G_real: 0.2221\n",
      "=> EPOCH 30 | Time: 40s | D_loss: 1.1525 | G_loss: 1.6531 | D_real: 0.5041 | D_fake: 0.2799 | G_real: 0.2161\n",
      "=> EPOCH 31 | Time: 40s | D_loss: 1.1401 | G_loss: 1.6345 | D_real: 0.5217 | D_fake: 0.2835 | G_real: 0.2196\n",
      "=> EPOCH 32 | Time: 39s | D_loss: 1.1411 | G_loss: 1.6182 | D_real: 0.5184 | D_fake: 0.2846 | G_real: 0.2229\n",
      "=> EPOCH 33 | Time: 40s | D_loss: 1.1564 | G_loss: 1.6499 | D_real: 0.5198 | D_fake: 0.2878 | G_real: 0.2190\n",
      "=> EPOCH 34 | Time: 39s | D_loss: 1.1349 | G_loss: 1.6170 | D_real: 0.5186 | D_fake: 0.2793 | G_real: 0.2222\n",
      "=> EPOCH 35 | Time: 39s | D_loss: 1.1315 | G_loss: 1.6244 | D_real: 0.5162 | D_fake: 0.2815 | G_real: 0.2217\n",
      "=> EPOCH 36 | Time: 38s | D_loss: 1.1401 | G_loss: 1.6488 | D_real: 0.5059 | D_fake: 0.2719 | G_real: 0.2159\n",
      "=> EPOCH 37 | Time: 38s | D_loss: 1.1309 | G_loss: 1.6088 | D_real: 0.5109 | D_fake: 0.2788 | G_real: 0.2235\n",
      "=> EPOCH 38 | Time: 39s | D_loss: 1.1114 | G_loss: 1.5834 | D_real: 0.5320 | D_fake: 0.2830 | G_real: 0.2270\n",
      "=> EPOCH 39 | Time: 38s | D_loss: 1.1058 | G_loss: 1.5895 | D_real: 0.5174 | D_fake: 0.2731 | G_real: 0.2249\n",
      "=> EPOCH 40 | Time: 38s | D_loss: 1.1294 | G_loss: 1.6149 | D_real: 0.5076 | D_fake: 0.2701 | G_real: 0.2197\n",
      "=> EPOCH 41 | Time: 39s | D_loss: 1.1751 | G_loss: 1.6783 | D_real: 0.4981 | D_fake: 0.2634 | G_real: 0.2120\n",
      "=> EPOCH 42 | Time: 38s | D_loss: 1.0893 | G_loss: 1.5570 | D_real: 0.5309 | D_fake: 0.2755 | G_real: 0.2312\n",
      "=> EPOCH 43 | Time: 38s | D_loss: 1.1238 | G_loss: 1.6173 | D_real: 0.5103 | D_fake: 0.2692 | G_real: 0.2211\n",
      "=> EPOCH 44 | Time: 37s | D_loss: 1.0699 | G_loss: 1.5242 | D_real: 0.5374 | D_fake: 0.2805 | G_real: 0.2365\n",
      "=> EPOCH 45 | Time: 38s | D_loss: 1.1343 | G_loss: 1.6205 | D_real: 0.5162 | D_fake: 0.2738 | G_real: 0.2247\n",
      "=> EPOCH 46 | Time: 38s | D_loss: 1.0919 | G_loss: 1.5653 | D_real: 0.5334 | D_fake: 0.2771 | G_real: 0.2304\n",
      "=> EPOCH 47 | Time: 37s | D_loss: 1.1008 | G_loss: 1.5735 | D_real: 0.5172 | D_fake: 0.2667 | G_real: 0.2278\n",
      "=> EPOCH 48 | Time: 37s | D_loss: 1.1572 | G_loss: 1.6528 | D_real: 0.4945 | D_fake: 0.2602 | G_real: 0.2164\n",
      "=> EPOCH 49 | Time: 37s | D_loss: 1.1011 | G_loss: 1.5767 | D_real: 0.5201 | D_fake: 0.2691 | G_real: 0.2262\n",
      "=> EPOCH 50 | Time: 37s | D_loss: 1.1053 | G_loss: 1.5982 | D_real: 0.5139 | D_fake: 0.2655 | G_real: 0.2232\n",
      "=> EPOCH 51 | Time: 37s | D_loss: 1.0981 | G_loss: 1.5736 | D_real: 0.5170 | D_fake: 0.2648 | G_real: 0.2272\n",
      "=> EPOCH 52 | Time: 37s | D_loss: 1.1407 | G_loss: 1.6319 | D_real: 0.5004 | D_fake: 0.2598 | G_real: 0.2214\n",
      "=> EPOCH 53 | Time: 36s | D_loss: 1.0755 | G_loss: 1.5385 | D_real: 0.5270 | D_fake: 0.2670 | G_real: 0.2327\n",
      "=> EPOCH 54 | Time: 36s | D_loss: 1.1652 | G_loss: 1.6712 | D_real: 0.4916 | D_fake: 0.2528 | G_real: 0.2162\n",
      "=> EPOCH 55 | Time: 36s | D_loss: 1.1201 | G_loss: 1.6099 | D_real: 0.5124 | D_fake: 0.2608 | G_real: 0.2248\n",
      "=> EPOCH 56 | Time: 36s | D_loss: 1.0943 | G_loss: 1.5733 | D_real: 0.5138 | D_fake: 0.2634 | G_real: 0.2285\n",
      "=> EPOCH 57 | Time: 37s | D_loss: 1.0967 | G_loss: 1.5727 | D_real: 0.5314 | D_fake: 0.2699 | G_real: 0.2309\n",
      "=> EPOCH 58 | Time: 36s | D_loss: 1.0890 | G_loss: 1.5590 | D_real: 0.5279 | D_fake: 0.2709 | G_real: 0.2363\n",
      "=> EPOCH 59 | Time: 36s | D_loss: 1.0958 | G_loss: 1.5683 | D_real: 0.5107 | D_fake: 0.2613 | G_real: 0.2273\n",
      "=> EPOCH 60 | Time: 36s | D_loss: 1.0922 | G_loss: 1.5612 | D_real: 0.5241 | D_fake: 0.2677 | G_real: 0.2318\n",
      "=> EPOCH 61 | Time: 36s | D_loss: 1.0737 | G_loss: 1.5351 | D_real: 0.5355 | D_fake: 0.2673 | G_real: 0.2373\n",
      "=> EPOCH 62 | Time: 36s | D_loss: 1.0748 | G_loss: 1.5354 | D_real: 0.5296 | D_fake: 0.2678 | G_real: 0.2352\n",
      "=> EPOCH 63 | Time: 35s | D_loss: 1.0881 | G_loss: 1.5575 | D_real: 0.5079 | D_fake: 0.2540 | G_real: 0.2277\n",
      "=> EPOCH 64 | Time: 36s | D_loss: 1.1141 | G_loss: 1.5999 | D_real: 0.5131 | D_fake: 0.2567 | G_real: 0.2263\n",
      "=> EPOCH 65 | Time: 36s | D_loss: 1.0421 | G_loss: 1.4896 | D_real: 0.5493 | D_fake: 0.2733 | G_real: 0.2444\n",
      "=> EPOCH 66 | Time: 35s | D_loss: 1.1178 | G_loss: 1.6031 | D_real: 0.4985 | D_fake: 0.2502 | G_real: 0.2233\n",
      "=> EPOCH 67 | Time: 35s | D_loss: 1.0479 | G_loss: 1.5170 | D_real: 0.5359 | D_fake: 0.2644 | G_real: 0.2372\n",
      "=> EPOCH 68 | Time: 36s | D_loss: 1.0941 | G_loss: 1.5664 | D_real: 0.5225 | D_fake: 0.2603 | G_real: 0.2305\n",
      "=> EPOCH 69 | Time: 35s | D_loss: 1.1051 | G_loss: 1.5770 | D_real: 0.5004 | D_fake: 0.2509 | G_real: 0.2258\n",
      "=> EPOCH 70 | Time: 35s | D_loss: 1.1269 | G_loss: 1.6077 | D_real: 0.5140 | D_fake: 0.2567 | G_real: 0.2280\n",
      "=> EPOCH 71 | Time: 36s | D_loss: 1.1147 | G_loss: 1.6027 | D_real: 0.5110 | D_fake: 0.2565 | G_real: 0.2250\n",
      "=> EPOCH 72 | Time: 35s | D_loss: 1.0986 | G_loss: 1.5740 | D_real: 0.5036 | D_fake: 0.2520 | G_real: 0.2263\n",
      "=> EPOCH 73 | Time: 35s | D_loss: 1.1062 | G_loss: 1.5937 | D_real: 0.5190 | D_fake: 0.2550 | G_real: 0.2290\n",
      "=> EPOCH 74 | Time: 35s | D_loss: 1.1022 | G_loss: 1.5774 | D_real: 0.5018 | D_fake: 0.2530 | G_real: 0.2273\n",
      "=> EPOCH 75 | Time: 36s | D_loss: 1.1658 | G_loss: 1.6741 | D_real: 0.5014 | D_fake: 0.2503 | G_real: 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 76 | Time: 35s | D_loss: 1.0600 | G_loss: 1.5322 | D_real: 0.5383 | D_fake: 0.2645 | G_real: 0.2377\n",
      "=> EPOCH 77 | Time: 35s | D_loss: 1.0227 | G_loss: 1.4787 | D_real: 0.5572 | D_fake: 0.2716 | G_real: 0.2462\n",
      "=> EPOCH 78 | Time: 35s | D_loss: 1.0822 | G_loss: 1.5659 | D_real: 0.5202 | D_fake: 0.2568 | G_real: 0.2322\n",
      "=> EPOCH 79 | Time: 34s | D_loss: 1.1130 | G_loss: 1.5879 | D_real: 0.4997 | D_fake: 0.2488 | G_real: 0.2272\n",
      "=> EPOCH 80 | Time: 35s | D_loss: 1.1068 | G_loss: 1.6020 | D_real: 0.4972 | D_fake: 0.2466 | G_real: 0.2241\n",
      "=> EPOCH 81 | Time: 35s | D_loss: 1.1377 | G_loss: 1.6531 | D_real: 0.5008 | D_fake: 0.2449 | G_real: 0.2206\n",
      "=> EPOCH 82 | Time: 35s | D_loss: 1.0975 | G_loss: 1.5660 | D_real: 0.5243 | D_fake: 0.2618 | G_real: 0.2350\n",
      "=> EPOCH 83 | Time: 35s | D_loss: 1.1768 | G_loss: 1.6849 | D_real: 0.4864 | D_fake: 0.2430 | G_real: 0.2163\n",
      "=> EPOCH 84 | Time: 35s | D_loss: 1.1053 | G_loss: 1.5841 | D_real: 0.5215 | D_fake: 0.2553 | G_real: 0.2299\n",
      "=> EPOCH 85 | Time: 35s | D_loss: 1.1098 | G_loss: 1.5839 | D_real: 0.5121 | D_fake: 0.2564 | G_real: 0.2311\n",
      "=> EPOCH 86 | Time: 35s | D_loss: 1.1137 | G_loss: 1.5930 | D_real: 0.5128 | D_fake: 0.2531 | G_real: 0.2280\n",
      "=> EPOCH 87 | Time: 35s | D_loss: 1.1745 | G_loss: 1.6825 | D_real: 0.4886 | D_fake: 0.2437 | G_real: 0.2157\n",
      "=> EPOCH 88 | Time: 35s | D_loss: 1.0318 | G_loss: 1.4775 | D_real: 0.5485 | D_fake: 0.2669 | G_real: 0.2458\n",
      "=> EPOCH 89 | Time: 35s | D_loss: 1.1120 | G_loss: 1.6018 | D_real: 0.5153 | D_fake: 0.2498 | G_real: 0.2272\n",
      "=> EPOCH 90 | Time: 35s | D_loss: 1.0642 | G_loss: 1.5214 | D_real: 0.5371 | D_fake: 0.2665 | G_real: 0.2435\n",
      "=> EPOCH 91 | Time: 34s | D_loss: 1.1245 | G_loss: 1.6271 | D_real: 0.5155 | D_fake: 0.2498 | G_real: 0.2268\n",
      "=> EPOCH 92 | Time: 35s | D_loss: 1.1642 | G_loss: 1.6801 | D_real: 0.5103 | D_fake: 0.2485 | G_real: 0.2230\n",
      "=> EPOCH 93 | Time: 35s | D_loss: 1.1845 | G_loss: 1.6912 | D_real: 0.4928 | D_fake: 0.2462 | G_real: 0.2208\n",
      "=> EPOCH 94 | Time: 35s | D_loss: 1.1064 | G_loss: 1.5951 | D_real: 0.5252 | D_fake: 0.2570 | G_real: 0.2326\n",
      "=> EPOCH 95 | Time: 34s | D_loss: 1.0446 | G_loss: 1.5097 | D_real: 0.5436 | D_fake: 0.2646 | G_real: 0.2417\n",
      "=> EPOCH 96 | Time: 35s | D_loss: 1.2132 | G_loss: 1.7445 | D_real: 0.4938 | D_fake: 0.2452 | G_real: 0.2182\n",
      "=> EPOCH 97 | Time: 35s | D_loss: 1.1440 | G_loss: 1.6387 | D_real: 0.5334 | D_fake: 0.2619 | G_real: 0.2367\n",
      "=> EPOCH 98 | Time: 35s | D_loss: 1.1453 | G_loss: 1.6486 | D_real: 0.5168 | D_fake: 0.2553 | G_real: 0.2288\n",
      "=> EPOCH 99 | Time: 35s | D_loss: 1.0302 | G_loss: 1.4772 | D_real: 0.5668 | D_fake: 0.2724 | G_real: 0.2497\n"
     ]
    }
   ],
   "source": [
    "result_losses = Results(args.loss_results)\n",
    "for epoch in range(0, args.epochs):\n",
    "    train(args, dataloader, netG, netD, G_optimizer, D_optimizer,\n",
    "          criterion, epoch, result_losses)\n",
    "    generate(args, netG, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_losses.save_to_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one REAL Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample, _ = iter(dataloader).next()\n",
    "save_image(sample, os.path.join(args.results, \"real_sample.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "246px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
