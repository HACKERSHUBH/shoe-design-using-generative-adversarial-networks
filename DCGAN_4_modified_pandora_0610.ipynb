{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of DCGAN with normalize input and one-sided label smoothing:\n",
    "- Number of epochs: 100\n",
    "- lr: 0.0002\n",
    "- Add results dir for images and loss\n",
    "- Add weight_decay: 1e-4\n",
    "\n",
    "- input: normalize (0.5, 0.5, 0.5)\n",
    "- sided_label real: 0.9 ```torch.from_numpy(np.full(batch_size, 0.9, np.float32))```\n",
    "- fake label: 0.3\n",
    "- Freezing: stop update D when loss D < 0.7 loss G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': './data/pandora/',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'image_size': 340,\n",
    "    'scale_size': 64,\n",
    "    'z_dim': 100,\n",
    "    'G_features': 64,\n",
    "    'D_features': 64,\n",
    "    'image_channels': 3,\n",
    "    'beta1': 0.5,\n",
    "    'cuda': True,\n",
    "    'seed': 7,\n",
    "    'workers': 2,\n",
    "    'results': './resultsDCGAN4_pandora_0610/'\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "args.image_results = args.results + 'images/'\n",
    "args.loss_results = args.results + 'loss/'\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.makedirs(args.data_path)\n",
    "if not os.path.isdir(args.results):\n",
    "    os.makedirs(args.results)\n",
    "if not os.path.isdir(args.image_results):\n",
    "    os.makedirs(args.image_results)\n",
    "if not os.path.isdir(args.loss_results):\n",
    "    os.makedirs(args.loss_results)\n",
    "    \n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: all iamges have size 136x102**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from folder import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "to_image = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(image_root, batch_size, scale_size, num_workers=2, shuffle=True):\n",
    "    #image_root = os.path.join(root, 'splits', split)\n",
    "    dataset = ImageFolder(root=image_root, transform=transforms.Compose([\n",
    "            transforms.Scale(scale_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=int(num_workers))\n",
    "    #data_loader.shape = [int(num) for num in dataset[0][0].size()]\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 662 images in subfolders of: ./data/pandora/\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_loader(args.data_path, args.batch_size, args.scale_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x64x64]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_image = 0\n",
    "for data, _ in dataloader:\n",
    "    print(data[0])\n",
    "    test_image = data[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAFtUlEQVR4nO2ZQWvkyBWA3z6KoiiE\nEEKIRojGaYzpGDMYYxpjBmPCsMxhD8HHZQ9LfklO+QFLDiGnnEIOYQ9DGIYwLIMZzGJMY5qmaUSj\nNEI0jRCNKEQhiuJNDnMJS3LqWpSF/u7S01f1Xknv6YtPnz7BLxns+wH25SDQNweBvjkI9M1BoG8O\nAn1zEOibg0DfHAT65iDQNweBvmHO70gEZI3RSlUlEgETXEru+Ux4jDFEx0vmWEBrvVsv1ep5V2yt\nyjkLLXDk2gDnUXp8dRumIy6kw4hfuJoLEZC1dvX4ofzhH23jcRl4MG23HfMjLzBl5WNngyEcvfr6\n6PyKCYaOstfNDhBRXSzKWb58+BDrOcNBxJnGoI4m0mOeePbsynKBbbd496Et66Or8yA5cpJODgSI\nSKkmv39X3BcWtZViux54pxO5exuze88iKKNgwlWpbK6tWmTvtKnGX96FYbS/g4M1KMvyzfd/35Ur\nZH5Tmcb48eRcq3JnZWfHEJ21PFIM2fmNEQOlyECQz6d//O67+XxORD0LENF8PgeATmurykHqxTyr\n8j/L8nviIRxPKL4IY38oH9ePfwrUo386MIgG+dHo+P3793tGh/1TiIh01wkhdGOoG+1qZeM4Do63\nUtjNMg6SbmMX03sjX8Yhy3YfrbIBxl3ThJ4sy5KI9swiBwKqaci0KIP4xKPlk259HP0mGVnRQJk/\n2a4djy/WcAodl800Zit5ebkoOCIOh8M9ozsQYIyFYTibZl45N9S1MrR15p9tdblaZtPR9e8IvCZ/\nH/KZolAG1PBEZYuqXpg8rap6fwEHNZAm6f2Hj5Yig+dtl57FBqp7Xs1OjsfAA5CeRO63M9E9QbWq\nC0Z1aq2XJIOLi4v9i9jBMbrK82++/SaqVrZTotFblTK8hICgWdp2Khl17Q6jV4b7m2zGZWEhkNJT\nqn18fLq7u+tZwFo7SGIkP5t/lGSgyvwg8OOBho63SFiaZhsIr4uS3Uoz4wujFCFDK4QYj8f7vwcc\nFHGxXh8lsc9YoV9oT5rijcEBCMjKhvjZ+eR0/uPbhN5R1TBbb+l1QMzop7qqlGr3jO5AABHTdEjU\nGTKRfq6Z4dAqvYqacpSeNf7xIu88JvV6IeIUQw+Zws1TDd3pMH0Rxv3vAGMsTdNtsaq2m2IlpCga\nG1l7suGjcVyJ3QM0NUhv3b72NAqqmm0NnW8kMO4mhfa+HlEI0aq23ayLxaJuAJuSsmey1u6qTuWM\ntomvIs9gNmO6FdJrqpYha9uWc75ndHCSQr7v+2GUnl7qzVJbJfBfMv4Va9e1OMoK3/PEhaekekNs\n11VVg5Gh9vXdt+e3r6Io6l8AAHzfn1xfY7XelIFoZ03z601zxvVm1C28emurdtmaPI/9cBBIXOz0\nxeTs/PomTRMnn9POGhprTJEVP/zlD6t//q1cEfdEmhrgsTGdkH6ZMd6ukkl6+vXvb377VRQHrtpx\nZwIAQNYW2XP+PM2n0+3zg6rKzcYDjkmswT8ZX19NvrwdXd1K6bmKCI4FiIjImK5YztZPD1U203UN\nwPxhkr64Ob68itMhIrrt610KWLLbPFvPpvl0unl+aKpiuxHIxSAxLDw5e/ny/Pbm6MXF/2tTT6Tq\n3dPbv5bT+3ZrUHA/ZOglRFZK0SnJUEWjwej6q+Tk2MkB+hk3AkSk6mqz3oLeWaO7zkNGvm9th8Qs\nl1K3KDhyDh3IIPKjNOFc7B8XXDX1xhiyJgx9iDwGFhEJiJBZw5GB4ATWWiAA8kgCkOkMImPMQXQ3\nAkDEGAcpkAGSJUBExtCCRABCBpYYt4SMCDhYS2SttU4K2oEAIjLOQUoGDIAALBADRERCACBLiAgM\nARAsAQMiQHCy/OCkBj53VT/treg/31QWAH6yWK7OU5fH6P/ms9vPMgl3P53+b/yMQ/xf/P+Bg0Df\nHAT65iDQNweBvjkI9M2/AXWyItcyrhwmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FFA1DC7E8D0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_image(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(args.z_dim, args.G_features * 8,\n",
    "                               4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(args.G_features * 8, args.G_features * 4,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(args.G_features * 4, args.G_features * 2,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(args.G_features * 2, args.G_features,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(args.G_features, args.image_channels,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # custom weight initialization\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                init.normal(m.weight, mean=0, std=0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.normal(m.weight, mean=1, std=0.02)\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(args.image_channels, args.D_features,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(args.D_features, args.D_features * 2,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(args.D_features * 2, args.D_features * 4,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(args.D_features * 4, args.D_features * 8,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(args.D_features * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # custom weight initialization\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                init.normal(m.weight, mean=0, std=0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.normal(m.weight, mean=1, std=0.02)\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Results():\n",
    "    def __init__(self, results_path):\n",
    "        self.D_losses = []\n",
    "        self.G_losses = []\n",
    "        self.D_reals = []\n",
    "        self.D_fakes = []\n",
    "        self.G_reals = []\n",
    "        self.results_path = results_path\n",
    "    \n",
    "    def save_losses(self, D_loss, G_loss, D_real, D_fake, G_real):\n",
    "        self.D_losses.append(D_loss)\n",
    "        self.G_losses.append(G_loss)\n",
    "        self.D_reals.append(D_real)\n",
    "        self.D_fakes.append(D_fake)\n",
    "        self.G_reals.append(G_real)\n",
    "        \n",
    "    def save_to_disk(self):\n",
    "        f = open(self.results_path + \"D_losses.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_losses, f)\n",
    "        f= open(self.results_path + \"G_losses.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_losses, f)\n",
    "        f = open(self.results_path + \"D_reals.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_reals, f)\n",
    "        f = open(self.results_path + \"D_fakes.pkl\", \"wb\")\n",
    "        pickle.dump(self.D_fakes, f)\n",
    "        f = open(self.results_path + \"G_reals.pkl\", \"wb\")\n",
    "        pickle.dump(self.G_reals, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(args, data_loader, netG, netD, G_optimizer, D_optimizer,\n",
    "          criterion, epoch, result_losses):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    D_reals = AverageValueMeter()\n",
    "    D_fakes = AverageValueMeter()\n",
    "    G_reals = AverageValueMeter()\n",
    "    \n",
    "    start = time.time()\n",
    "    # call Variable after .cuda()\n",
    "    for i, (real, _) in enumerate(data_loader):\n",
    "        batch_size = real.size(0)\n",
    "        real_label = torch.from_numpy(np.full(batch_size, 0.9, np.float32)) #modify here\n",
    "        fake_label = torch.from_numpy(np.full(batch_size, 0.3, np.float32))\n",
    "        z = torch.randn(batch_size, args.z_dim, 1, 1)\n",
    "        \n",
    "        if args.cuda:\n",
    "            real_label = real_label.cuda()\n",
    "            fake_label = fake_label.cuda()\n",
    "            real = real.cuda()\n",
    "            z = z.cuda()\n",
    "        real_label = Variable(real_label)\n",
    "        fake_label = Variable(fake_label)\n",
    "        real = Variable(real)\n",
    "        z = Variable(z)\n",
    "        \n",
    "        if D_losses.value()[0] < 0.7*G_losses.value()[0]:\n",
    "            # Stop training D\n",
    "            #----------TRAIN D---------------\n",
    "            # train with real\n",
    "            real_output = netD(real)\n",
    "            D_real_loss = criterion(real_output, real_label)\n",
    "            D_real = real_output.data.mean()\n",
    "        \n",
    "            # train with fake\n",
    "            fake = netG(z)\n",
    "            fake_output = netD(fake.detach())\n",
    "            D_fake_loss = criterion(fake_output, fake_label)\n",
    "            D_fake = fake_output.data.mean()\n",
    "        \n",
    "            # loss D\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "            #netD.zero_grad()\n",
    "            #D_loss.backward()\n",
    "            #D_optimizer.step()\n",
    "            \n",
    "            #----------TRAIN G---------------\n",
    "            output = netD(fake)\n",
    "            G_loss = criterion(output, real_label)\n",
    "            G_real = output.data.mean()\n",
    "            netG.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()    \n",
    "        else:\n",
    "            #----------TRAIN D---------------\n",
    "            # train with real\n",
    "            real_output = netD(real)\n",
    "            D_real_loss = criterion(real_output, real_label)\n",
    "            D_real = real_output.data.mean()\n",
    "        \n",
    "            # train with fake\n",
    "            fake = netG(z)\n",
    "            fake_output = netD(fake.detach())\n",
    "            D_fake_loss = criterion(fake_output, fake_label)\n",
    "            D_fake = fake_output.data.mean()\n",
    "        \n",
    "            # loss D\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "            netD.zero_grad()\n",
    "            D_loss.backward()\n",
    "            D_optimizer.step()\n",
    "            \n",
    "            #----------TRAIN G---------------\n",
    "            output = netD(fake)\n",
    "            G_loss = criterion(output, real_label)\n",
    "            G_real = output.data.mean()\n",
    "            netG.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # update loss\n",
    "        D_losses.add(D_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        G_losses.add(G_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        D_reals.add(D_real * batch_size, batch_size)\n",
    "        D_fakes.add(D_fake * batch_size, batch_size)\n",
    "        G_reals.add(G_real * batch_size, batch_size)\n",
    "        \n",
    "    print(\"=> EPOCH {} | Time: {}s | D_loss: {:.4f} | G_loss: {:.4f}\"\n",
    "          \" | D_real: {:.4f} | D_fake: {:.4f} | G_real: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start), D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0]))\n",
    "    result_losses.save_losses(D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_reals.value()[0],\n",
    "                  D_fakes.value()[0], G_reals.value()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(args, netG, epoch):\n",
    "    z = torch.randn(args.batch_size, args.z_dim, 1, 1)\n",
    "    if args.cuda:\n",
    "        z = z.cuda()\n",
    "    fake = netG(Variable(z, volatile=True))\n",
    "    save_image(fake.data.cpu(), os.path.join(args.image_results,\n",
    "        \"fake_sample_epoch_{:02d}.png\".format(epoch)), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG()\n",
    "netD = _netD()\n",
    "criterion = nn.BCELoss()\n",
    "if args.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_optimizer = optim.Adam(netD.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999), weight_decay=1e-4)\n",
    "G_optimizer = optim.Adam(netG.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 0 | Time: 3s | D_loss: 2.1808 | G_loss: 3.3333 | D_real: 0.8985 | D_fake: 0.5349 | G_real: 0.1343\n",
      "=> EPOCH 1 | Time: 2s | D_loss: 2.5692 | G_loss: 3.6573 | D_real: 0.6559 | D_fake: 0.5219 | G_real: 0.3204\n",
      "=> EPOCH 2 | Time: 2s | D_loss: 2.4744 | G_loss: 3.6508 | D_real: 0.8397 | D_fake: 0.4929 | G_real: 0.3660\n",
      "=> EPOCH 3 | Time: 2s | D_loss: 2.5536 | G_loss: 4.3916 | D_real: 0.9192 | D_fake: 0.3921 | G_real: 0.2978\n",
      "=> EPOCH 4 | Time: 2s | D_loss: 2.8174 | G_loss: 4.3077 | D_real: 0.7375 | D_fake: 0.6282 | G_real: 0.5080\n",
      "=> EPOCH 5 | Time: 2s | D_loss: 2.9116 | G_loss: 5.0235 | D_real: 0.9164 | D_fake: 0.4107 | G_real: 0.3172\n",
      "=> EPOCH 6 | Time: 2s | D_loss: 2.7101 | G_loss: 5.5957 | D_real: 0.8810 | D_fake: 0.5543 | G_real: 0.4080\n",
      "=> EPOCH 7 | Time: 2s | D_loss: 2.2076 | G_loss: 3.3375 | D_real: 0.8819 | D_fake: 0.4825 | G_real: 0.3914\n",
      "=> EPOCH 8 | Time: 2s | D_loss: 2.6984 | G_loss: 4.9918 | D_real: 0.7286 | D_fake: 0.4992 | G_real: 0.4096\n",
      "=> EPOCH 9 | Time: 2s | D_loss: 2.8947 | G_loss: 4.9604 | D_real: 0.6057 | D_fake: 0.5035 | G_real: 0.4181\n",
      "=> EPOCH 10 | Time: 2s | D_loss: 2.6484 | G_loss: 4.9609 | D_real: 0.7927 | D_fake: 0.4994 | G_real: 0.4161\n",
      "=> EPOCH 11 | Time: 2s | D_loss: 2.7355 | G_loss: 5.3896 | D_real: 0.7946 | D_fake: 0.4933 | G_real: 0.4078\n",
      "=> EPOCH 12 | Time: 2s | D_loss: 2.7383 | G_loss: 5.0519 | D_real: 0.7286 | D_fake: 0.5145 | G_real: 0.4297\n",
      "=> EPOCH 13 | Time: 2s | D_loss: 2.7125 | G_loss: 4.9073 | D_real: 0.7906 | D_fake: 0.5233 | G_real: 0.4409\n",
      "=> EPOCH 14 | Time: 2s | D_loss: 2.8057 | G_loss: 5.1006 | D_real: 0.7036 | D_fake: 0.5169 | G_real: 0.4337\n",
      "=> EPOCH 15 | Time: 2s | D_loss: 2.9469 | G_loss: 5.3398 | D_real: 0.5909 | D_fake: 0.4816 | G_real: 0.3979\n",
      "=> EPOCH 16 | Time: 2s | D_loss: 2.7710 | G_loss: 5.1192 | D_real: 0.6490 | D_fake: 0.4549 | G_real: 0.3706\n",
      "=> EPOCH 17 | Time: 2s | D_loss: 2.6894 | G_loss: 5.2932 | D_real: 0.6939 | D_fake: 0.4118 | G_real: 0.3232\n",
      "=> EPOCH 18 | Time: 2s | D_loss: 2.8406 | G_loss: 5.0467 | D_real: 0.6143 | D_fake: 0.4708 | G_real: 0.3840\n",
      "=> EPOCH 19 | Time: 2s | D_loss: 2.9134 | G_loss: 4.7123 | D_real: 0.5297 | D_fake: 0.4468 | G_real: 0.3591\n",
      "=> EPOCH 20 | Time: 2s | D_loss: 3.0150 | G_loss: 5.0959 | D_real: 0.4857 | D_fake: 0.3696 | G_real: 0.2787\n",
      "=> EPOCH 21 | Time: 2s | D_loss: 2.6258 | G_loss: 4.5548 | D_real: 0.6378 | D_fake: 0.4091 | G_real: 0.3180\n",
      "=> EPOCH 22 | Time: 2s | D_loss: 3.7023 | G_loss: 5.4669 | D_real: 0.2794 | D_fake: 0.3642 | G_real: 0.2762\n",
      "=> EPOCH 23 | Time: 2s | D_loss: 3.6117 | G_loss: 5.1671 | D_real: 0.4334 | D_fake: 0.4337 | G_real: 0.2534\n",
      "=> EPOCH 24 | Time: 3s | D_loss: 2.8697 | G_loss: 2.2811 | D_real: 0.6547 | D_fake: 0.5026 | G_real: 0.3303\n",
      "=> EPOCH 25 | Time: 2s | D_loss: 1.9219 | G_loss: 2.0498 | D_real: 0.5994 | D_fake: 0.4609 | G_real: 0.2779\n",
      "=> EPOCH 26 | Time: 3s | D_loss: 1.3215 | G_loss: 1.4654 | D_real: 0.7304 | D_fake: 0.4476 | G_real: 0.2846\n",
      "=> EPOCH 27 | Time: 2s | D_loss: 1.6716 | G_loss: 1.8420 | D_real: 0.6405 | D_fake: 0.3962 | G_real: 0.3174\n",
      "=> EPOCH 28 | Time: 3s | D_loss: 1.2816 | G_loss: 1.4508 | D_real: 0.7468 | D_fake: 0.4171 | G_real: 0.3256\n",
      "=> EPOCH 29 | Time: 3s | D_loss: 1.1741 | G_loss: 1.3793 | D_real: 0.7796 | D_fake: 0.4473 | G_real: 0.2466\n",
      "=> EPOCH 30 | Time: 3s | D_loss: 1.6470 | G_loss: 1.4447 | D_real: 0.7074 | D_fake: 0.4806 | G_real: 0.3792\n",
      "=> EPOCH 31 | Time: 3s | D_loss: 1.2798 | G_loss: 1.2469 | D_real: 0.7594 | D_fake: 0.4598 | G_real: 0.3346\n",
      "=> EPOCH 32 | Time: 3s | D_loss: 1.2649 | G_loss: 1.2653 | D_real: 0.7571 | D_fake: 0.4490 | G_real: 0.3512\n",
      "=> EPOCH 33 | Time: 3s | D_loss: 1.1862 | G_loss: 1.2867 | D_real: 0.7982 | D_fake: 0.4235 | G_real: 0.3210\n",
      "=> EPOCH 34 | Time: 3s | D_loss: 1.1977 | G_loss: 1.2405 | D_real: 0.7784 | D_fake: 0.4110 | G_real: 0.3391\n",
      "=> EPOCH 35 | Time: 3s | D_loss: 1.2027 | G_loss: 1.3839 | D_real: 0.7916 | D_fake: 0.3995 | G_real: 0.3187\n",
      "=> EPOCH 36 | Time: 3s | D_loss: 1.2198 | G_loss: 1.3527 | D_real: 0.7803 | D_fake: 0.4049 | G_real: 0.3194\n",
      "=> EPOCH 37 | Time: 2s | D_loss: 1.5153 | G_loss: 1.7117 | D_real: 0.6501 | D_fake: 0.3955 | G_real: 0.2664\n",
      "=> EPOCH 38 | Time: 3s | D_loss: 1.2025 | G_loss: 1.3785 | D_real: 0.7759 | D_fake: 0.4294 | G_real: 0.3047\n",
      "=> EPOCH 39 | Time: 3s | D_loss: 1.1826 | G_loss: 1.3962 | D_real: 0.7900 | D_fake: 0.3998 | G_real: 0.3000\n",
      "=> EPOCH 40 | Time: 2s | D_loss: 1.3104 | G_loss: 1.5182 | D_real: 0.7223 | D_fake: 0.4271 | G_real: 0.2707\n",
      "=> EPOCH 41 | Time: 3s | D_loss: 1.3027 | G_loss: 1.5275 | D_real: 0.7507 | D_fake: 0.4349 | G_real: 0.3041\n",
      "=> EPOCH 42 | Time: 2s | D_loss: 1.5825 | G_loss: 1.6164 | D_real: 0.6683 | D_fake: 0.4459 | G_real: 0.2961\n",
      "=> EPOCH 43 | Time: 3s | D_loss: 1.1326 | G_loss: 1.3819 | D_real: 0.7795 | D_fake: 0.4251 | G_real: 0.2780\n",
      "=> EPOCH 44 | Time: 2s | D_loss: 1.2766 | G_loss: 1.5437 | D_real: 0.7327 | D_fake: 0.4126 | G_real: 0.2753\n",
      "=> EPOCH 45 | Time: 2s | D_loss: 1.2486 | G_loss: 1.5944 | D_real: 0.7379 | D_fake: 0.4246 | G_real: 0.2676\n",
      "=> EPOCH 46 | Time: 3s | D_loss: 1.2185 | G_loss: 1.3871 | D_real: 0.7536 | D_fake: 0.4246 | G_real: 0.3002\n",
      "=> EPOCH 47 | Time: 2s | D_loss: 1.3600 | G_loss: 1.6420 | D_real: 0.7068 | D_fake: 0.3874 | G_real: 0.2821\n",
      "=> EPOCH 48 | Time: 2s | D_loss: 1.2117 | G_loss: 1.3481 | D_real: 0.7606 | D_fake: 0.4256 | G_real: 0.3029\n",
      "=> EPOCH 49 | Time: 3s | D_loss: 1.1706 | G_loss: 1.3870 | D_real: 0.7707 | D_fake: 0.4200 | G_real: 0.2985\n",
      "=> EPOCH 50 | Time: 2s | D_loss: 1.2641 | G_loss: 1.5306 | D_real: 0.7372 | D_fake: 0.4028 | G_real: 0.2826\n",
      "=> EPOCH 51 | Time: 3s | D_loss: 1.1156 | G_loss: 1.4036 | D_real: 0.7991 | D_fake: 0.3915 | G_real: 0.2749\n",
      "=> EPOCH 52 | Time: 3s | D_loss: 1.2435 | G_loss: 1.4410 | D_real: 0.7572 | D_fake: 0.4296 | G_real: 0.2989\n",
      "=> EPOCH 53 | Time: 3s | D_loss: 1.1698 | G_loss: 1.4456 | D_real: 0.7716 | D_fake: 0.4165 | G_real: 0.2962\n",
      "=> EPOCH 54 | Time: 3s | D_loss: 1.1287 | G_loss: 1.4820 | D_real: 0.8010 | D_fake: 0.3963 | G_real: 0.2680\n",
      "=> EPOCH 55 | Time: 2s | D_loss: 1.2111 | G_loss: 1.5874 | D_real: 0.6978 | D_fake: 0.3973 | G_real: 0.2457\n",
      "=> EPOCH 56 | Time: 3s | D_loss: 1.2378 | G_loss: 1.4759 | D_real: 0.7707 | D_fake: 0.4102 | G_real: 0.2991\n",
      "=> EPOCH 57 | Time: 3s | D_loss: 1.1880 | G_loss: 1.4522 | D_real: 0.7596 | D_fake: 0.3930 | G_real: 0.2869\n",
      "=> EPOCH 58 | Time: 2s | D_loss: 1.4452 | G_loss: 1.6296 | D_real: 0.6934 | D_fake: 0.4169 | G_real: 0.3082\n",
      "=> EPOCH 59 | Time: 3s | D_loss: 1.1360 | G_loss: 1.3070 | D_real: 0.7626 | D_fake: 0.4675 | G_real: 0.2669\n",
      "=> EPOCH 60 | Time: 2s | D_loss: 1.1735 | G_loss: 1.6027 | D_real: 0.6928 | D_fake: 0.4107 | G_real: 0.2077\n",
      "=> EPOCH 61 | Time: 3s | D_loss: 1.2281 | G_loss: 1.3763 | D_real: 0.7596 | D_fake: 0.4181 | G_real: 0.3132\n",
      "=> EPOCH 62 | Time: 3s | D_loss: 1.1515 | G_loss: 1.4138 | D_real: 0.7800 | D_fake: 0.3984 | G_real: 0.2831\n",
      "=> EPOCH 63 | Time: 3s | D_loss: 1.1656 | G_loss: 1.5086 | D_real: 0.7537 | D_fake: 0.3848 | G_real: 0.2602\n",
      "=> EPOCH 64 | Time: 2s | D_loss: 1.2649 | G_loss: 1.5954 | D_real: 0.6989 | D_fake: 0.3982 | G_real: 0.2561\n",
      "=> EPOCH 65 | Time: 2s | D_loss: 1.1785 | G_loss: 1.6880 | D_real: 0.7048 | D_fake: 0.3746 | G_real: 0.2095\n",
      "=> EPOCH 66 | Time: 3s | D_loss: 1.2301 | G_loss: 1.4888 | D_real: 0.7611 | D_fake: 0.4087 | G_real: 0.2888\n",
      "=> EPOCH 67 | Time: 3s | D_loss: 1.0516 | G_loss: 1.3271 | D_real: 0.8153 | D_fake: 0.3701 | G_real: 0.2719\n",
      "=> EPOCH 68 | Time: 3s | D_loss: 1.0937 | G_loss: 1.4102 | D_real: 0.8138 | D_fake: 0.3839 | G_real: 0.2704\n",
      "=> EPOCH 69 | Time: 2s | D_loss: 1.1868 | G_loss: 1.6172 | D_real: 0.6915 | D_fake: 0.3170 | G_real: 0.2173\n",
      "=> EPOCH 70 | Time: 2s | D_loss: 1.3622 | G_loss: 1.9477 | D_real: 0.6731 | D_fake: 0.3257 | G_real: 0.1995\n",
      "=> EPOCH 71 | Time: 3s | D_loss: 1.3237 | G_loss: 1.7253 | D_real: 0.7332 | D_fake: 0.4318 | G_real: 0.2649\n",
      "=> EPOCH 72 | Time: 2s | D_loss: 1.1853 | G_loss: 1.3304 | D_real: 0.7389 | D_fake: 0.4292 | G_real: 0.2843\n",
      "=> EPOCH 73 | Time: 3s | D_loss: 1.1058 | G_loss: 1.1877 | D_real: 0.7623 | D_fake: 0.4318 | G_real: 0.3054\n",
      "=> EPOCH 74 | Time: 3s | D_loss: 1.0689 | G_loss: 1.2366 | D_real: 0.7910 | D_fake: 0.3950 | G_real: 0.2990\n",
      "=> EPOCH 75 | Time: 3s | D_loss: 1.1637 | G_loss: 1.4310 | D_real: 0.7829 | D_fake: 0.4075 | G_real: 0.2842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 76 | Time: 3s | D_loss: 1.0334 | G_loss: 1.2777 | D_real: 0.8106 | D_fake: 0.3812 | G_real: 0.2739\n",
      "=> EPOCH 77 | Time: 3s | D_loss: 1.0451 | G_loss: 1.2972 | D_real: 0.7921 | D_fake: 0.3924 | G_real: 0.2565\n",
      "=> EPOCH 78 | Time: 3s | D_loss: 1.1515 | G_loss: 1.5522 | D_real: 0.7787 | D_fake: 0.4029 | G_real: 0.2835\n",
      "=> EPOCH 79 | Time: 3s | D_loss: 1.5535 | G_loss: 1.6501 | D_real: 0.7431 | D_fake: 0.4215 | G_real: 0.3016\n",
      "=> EPOCH 80 | Time: 3s | D_loss: 1.1307 | G_loss: 1.2963 | D_real: 0.7547 | D_fake: 0.4289 | G_real: 0.2847\n",
      "=> EPOCH 81 | Time: 3s | D_loss: 1.0710 | G_loss: 1.2070 | D_real: 0.8015 | D_fake: 0.4223 | G_real: 0.2821\n",
      "=> EPOCH 82 | Time: 3s | D_loss: 1.1433 | G_loss: 1.3152 | D_real: 0.7695 | D_fake: 0.4205 | G_real: 0.3068\n",
      "=> EPOCH 83 | Time: 3s | D_loss: 1.0758 | G_loss: 1.3613 | D_real: 0.8009 | D_fake: 0.4215 | G_real: 0.2512\n",
      "=> EPOCH 84 | Time: 3s | D_loss: 1.0743 | G_loss: 1.3212 | D_real: 0.7911 | D_fake: 0.4012 | G_real: 0.2716\n",
      "=> EPOCH 85 | Time: 2s | D_loss: 1.2279 | G_loss: 1.5798 | D_real: 0.7174 | D_fake: 0.4136 | G_real: 0.2496\n",
      "=> EPOCH 86 | Time: 2s | D_loss: 1.2731 | G_loss: 1.3603 | D_real: 0.7256 | D_fake: 0.4355 | G_real: 0.3029\n",
      "=> EPOCH 87 | Time: 3s | D_loss: 1.0934 | G_loss: 1.2090 | D_real: 0.7590 | D_fake: 0.4309 | G_real: 0.2999\n",
      "=> EPOCH 88 | Time: 3s | D_loss: 1.0579 | G_loss: 1.1756 | D_real: 0.7878 | D_fake: 0.3965 | G_real: 0.2990\n",
      "=> EPOCH 89 | Time: 2s | D_loss: 1.1330 | G_loss: 1.3087 | D_real: 0.7360 | D_fake: 0.4137 | G_real: 0.2811\n",
      "=> EPOCH 90 | Time: 3s | D_loss: 1.1446 | G_loss: 1.2838 | D_real: 0.7633 | D_fake: 0.4267 | G_real: 0.2985\n",
      "=> EPOCH 91 | Time: 3s | D_loss: 1.1558 | G_loss: 1.2810 | D_real: 0.7688 | D_fake: 0.4389 | G_real: 0.3099\n",
      "=> EPOCH 92 | Time: 3s | D_loss: 1.0771 | G_loss: 1.2460 | D_real: 0.7882 | D_fake: 0.4117 | G_real: 0.3045\n",
      "=> EPOCH 93 | Time: 3s | D_loss: 1.1297 | G_loss: 1.2768 | D_real: 0.8045 | D_fake: 0.4288 | G_real: 0.2864\n",
      "=> EPOCH 94 | Time: 3s | D_loss: 1.1011 | G_loss: 1.3008 | D_real: 0.7876 | D_fake: 0.4173 | G_real: 0.3023\n",
      "=> EPOCH 95 | Time: 3s | D_loss: 1.1563 | G_loss: 1.3430 | D_real: 0.7745 | D_fake: 0.4552 | G_real: 0.2760\n",
      "=> EPOCH 96 | Time: 3s | D_loss: 1.3546 | G_loss: 1.5364 | D_real: 0.7029 | D_fake: 0.4554 | G_real: 0.2690\n",
      "=> EPOCH 97 | Time: 3s | D_loss: 1.1332 | G_loss: 1.2616 | D_real: 0.7564 | D_fake: 0.4331 | G_real: 0.2941\n",
      "=> EPOCH 98 | Time: 2s | D_loss: 1.2442 | G_loss: 1.4392 | D_real: 0.7075 | D_fake: 0.4156 | G_real: 0.2806\n",
      "=> EPOCH 99 | Time: 3s | D_loss: 1.1781 | G_loss: 1.2716 | D_real: 0.7490 | D_fake: 0.4402 | G_real: 0.3214\n"
     ]
    }
   ],
   "source": [
    "result_losses = Results(args.loss_results)\n",
    "for epoch in range(0, args.epochs):\n",
    "    train(args, dataloader, netG, netD, G_optimizer, D_optimizer,\n",
    "          criterion, epoch, result_losses)\n",
    "    generate(args, netG, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_losses.save_to_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one REAL Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample, _ = iter(dataloader).next()\n",
    "save_image(sample, os.path.join(args.results, \"real_sample.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "246px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
